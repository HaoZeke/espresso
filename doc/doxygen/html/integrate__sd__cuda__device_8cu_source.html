<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.9.1"/>
<title>ESPResSo 3.4-dev-1009-g69a2b86-dirty-git: integrate_sd_cuda_device.cu Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo_48x48.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">ESPResSo 3.4-dev-1009-g69a2b86-dirty-git
   </div>
   <div id="projectbrief">Extensible Simulation Package for Soft Matter Research</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.9.1 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>Globals</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('integrate__sd__cuda__device_8cu_source.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">integrate_sd_cuda_device.cu</div>  </div>
</div><!--header-->
<div class="contents">
<a href="integrate__sd__cuda__device_8cu.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/*</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">  Copyright (C) 2010,2012,2013,2014,2015 The ESPResSo project</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">  Copyright (C) 2002,2003,2004,2005,2006,2007,2008,2009,2010 </span></div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">    Max-Planck-Institute for Polymer Research, Theory Group</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">  </span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">  This file is part of ESPResSo.</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment">  </span></div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment">  ESPResSo is free software: you can redistribute it and/or modify</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment">  it under the terms of the GNU General Public License as published by</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment">  the Free Software Foundation, either version 3 of the License, or</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment">  (at your option) any later version.</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment">  </span></div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment">  ESPResSo is distributed in the hope that it will be useful,</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment">  but WITHOUT ANY WARRANTY; without even the implied warranty of</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment">  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span></div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment">  GNU General Public License for more details.</span></div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment">  </span></div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment">  You should have received a copy of the GNU General Public License</span></div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="comment">  along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;. </span></div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment">*/</span></div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;</div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="integrate__sd__cuda_8hpp.html">integrate_sd_cuda.hpp</a>&quot;</span></div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="integrate__sd__cuda__device_8hpp.html">integrate_sd_cuda_device.hpp</a>&quot;</span></div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#ifdef SD</span></div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;</div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="comment">/* *************************************************************************************************************** *</span></div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="comment"> * ********************************************    DEVICE-Functions   ******************************************** *</span></div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="comment"> * *************************************************************************************************************** */</span></div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="comment"></span></div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="comment">/// atomic add for doubles</span></div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="comment">/// address  : pointer to which the value should be added</span></div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="comment">/// inc      : value which should be added</span></div>
<div class="line"><a name="l00034"></a><span class="lineno"><a class="line" href="integrate__sd__cuda__device_8hpp.html#a7a73685d7bc0937fcbfe8fe789d59512">   34</a></span>&#160;<span class="comment"></span>__device__ <span class="keywordtype">double</span> <a class="code" href="integrate__sd__cuda__device_8cu.html#a7a73685d7bc0937fcbfe8fe789d59512">atomicAdd</a>(<span class="keywordtype">double</span> * address, <span class="keywordtype">double</span> inc){</div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;</div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;  <a class="code" href="integrate__sd__cuda__device_8hpp.html#aa5114a4fed348a29fb92123470476b1b">ull</a> *addressUll = (<a class="code" href="integrate__sd__cuda__device_8hpp.html#aa5114a4fed348a29fb92123470476b1b">ull</a>*) address;</div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;  <a class="code" href="integrate__sd__cuda__device_8hpp.html#aa5114a4fed348a29fb92123470476b1b">ull</a> oldValue=*addressUll;</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;  <a class="code" href="integrate__sd__cuda__device_8hpp.html#aa5114a4fed348a29fb92123470476b1b">ull</a> assumedValue;</div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;  assert(!<a class="code" href="utils_8hpp.html#a5197b278b9dd88d5c7509db1a9f76a56">isnan</a>(inc));</div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;  <span class="keywordflow">do</span> {</div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;    assumedValue=oldValue;</div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;    <a class="code" href="integrate__sd__cuda__device_8hpp.html#aa5114a4fed348a29fb92123470476b1b">ull</a> newValue = __double_as_longlong (__longlong_as_double(assumedValue)+inc);</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;    oldValue = atomicCAS(addressUll,assumedValue,newValue);</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;  }</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;  <span class="keywordflow">while</span> (oldValue != assumedValue);</div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;  <span class="keywordflow">return</span> __longlong_as_double(oldValue);</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;}</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="comment"></span></div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="comment">/// modulo function for integers as implemented in python</span></div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="comment">/// returns value % max </span></div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="comment">/// which is always positive</span></div>
<div class="line"><a name="l00052"></a><span class="lineno"><a class="line" href="integrate__sd__cuda__device_8hpp.html#afd3766568c64cd38df13659c1fea2cd7">   52</a></span>&#160;<span class="comment"></span>__device__ __inline__ <span class="keywordtype">int</span> <a class="code" href="integrate__sd__cuda__device_8cu.html#a2b80c8d16b0b0b8e9cd3a4f785980099">fold_back_up</a>(<span class="keywordtype">int</span> value, <span class="keywordtype">int</span> max){</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;  <span class="keywordflow">while</span> (value &lt; 0){</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;    value+=max;</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;  }</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;  <span class="keywordflow">while</span> (value &gt;= max){</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;    value-=max;</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;  }</div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;  <span class="keywordflow">return</span> value;</div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;}</div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="comment"></span></div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="comment">/// reduction function returning maximum of all value.</span></div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="comment">/// has to be called by all threads</span></div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment">/// shared_cache should be a pointer to shared memory of at least size blockDim.x</span></div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="comment">/// blockDim.x has to be an even number</span></div>
<div class="line"><a name="l00066"></a><span class="lineno"><a class="line" href="integrate__sd__cuda__device_8cu.html#a1c4c3921eac299713ff0ede5406ea077">   66</a></span>&#160;<span class="comment"></span>__device__ <span class="keywordtype">int</span> <a class="code" href="integrate__sd__cuda__device_8cu.html#a1c4c3921eac299713ff0ede5406ea077">reduce_max</a>(<span class="keywordtype">int</span> * shared_cache){</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> t=(blockDim.x+1)/2;t&gt;1;t=(t+1)/2){</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;    <span class="keywordflow">if</span> (threadIdx.x &lt; t){</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;      <span class="keywordflow">if</span> (shared_cache[threadIdx.x]&lt;shared_cache[threadIdx.x+t]){</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;        shared_cache[threadIdx.x]=shared_cache[threadIdx.x+t];</div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;      }</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    }</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;    __syncthreads();</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;  }</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;  <span class="keywordflow">if</span> (threadIdx.x==0){</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;    shared_cache[0]=shared_cache[0]&gt;shared_cache[1]?shared_cache[0]:shared_cache[1];</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;  }</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;  <span class="keywordflow">return</span> shared_cache[0];</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;}</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;</div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;</div>
<div class="line"><a name="l00082"></a><span class="lineno"><a class="line" href="integrate__sd__cuda__device_8hpp.html#a9d466f7fdce5c8c579290313509e6ea6">   82</a></span>&#160;__device__ <span class="keywordtype">int</span> <a class="code" href="integrate__sd__cuda__device_8cu.html#a1c4c3921eac299713ff0ede5406ea077">reduce_max</a>(<span class="keywordtype">int</span> * shared_cache, <span class="keywordtype">int</span> value){</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;  shared_cache[threadIdx.x]=value;</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;  <span class="comment">/*if (threadIdx.x == 0){</span></div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="comment">    if ((((blockDim.x+1)/2)*2) &gt; blockDim.x){</span></div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="comment">      shared_cache[blockDim.x+1]=0;</span></div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="comment">    }</span></div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="comment">  }*/</span></div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;  <span class="comment">//shared_cache[threadIdx.x+blockDim.x]=0;</span></div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;  __syncthreads();</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="integrate__sd__cuda__device_8cu.html#a1c4c3921eac299713ff0ede5406ea077">reduce_max</a>(shared_cache);</div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;}</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;<span class="comment"></span></div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;<span class="comment">/// reduction function returning sum of all values in shared_cache[0:blockDim.x-1]</span></div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;<span class="comment">/// has to be called by all threads</span></div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;<span class="comment">/// shared_cache should be a pointer to shared memory of at least size blockDim.x</span></div>
<div class="line"><a name="l00099"></a><span class="lineno"><a class="line" href="integrate__sd__cuda__device_8hpp.html#a7448fd635b1e54545cc6800aac0e63d6">   99</a></span>&#160;<span class="comment"></span>__device__ <span class="keywordtype">void</span> <a class="code" href="integrate__sd__cuda__device_8cu.html#a7448fd635b1e54545cc6800aac0e63d6">reduce_sum</a>(<a class="code" href="EwaldgpuForce_8cpp.html#afca8eb41f1c759484b22c425442d9aa1">real</a> * shared_cache){</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;<span class="preprocessor">#ifndef numThreadsPerBlock_is_power_of_two</span></div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;<span class="preprocessor">#error numThreadsPerBlock has to be a power of two for effective reduction</span></div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;  <span class="comment">//shared_cache[threadIdx.x]=value;</span></div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> t=(blockDim.x)/2;t&gt;0;t=t/2){</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;    <span class="keywordflow">if</span> (threadIdx.x &lt; t){</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;      shared_cache[threadIdx.x]=shared_cache[threadIdx.x]+shared_cache[threadIdx.x+t];</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;    }</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;    __syncthreads();</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;  }</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;}</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;<span class="comment"></span></div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;<span class="comment">/// function to avoid caching if reading from global memory</span></div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;<span class="comment">/// addr     : address from which the value should be read</span></div>
<div class="line"><a name="l00114"></a><span class="lineno"><a class="line" href="integrate__sd__cuda__device_8hpp.html#a577c549165753063e40436543a8b9166">  114</a></span>&#160;<span class="comment"></span>__device__ __inline__ <a class="code" href="EwaldgpuForce_8cpp.html#afca8eb41f1c759484b22c425442d9aa1">real</a> <a class="code" href="integrate__sd__cuda__device_8cu.html#a577c549165753063e40436543a8b9166">read_without_caching</a>( <span class="keyword">const</span> <a class="code" href="EwaldgpuForce_8cpp.html#afca8eb41f1c759484b22c425442d9aa1">real</a> * addr){</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;   <a class="code" href="EwaldgpuForce_8cpp.html#afca8eb41f1c759484b22c425442d9aa1">real</a> tmp;</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;<span class="preprocessor">#ifdef SD_USE_FLOAT</span></div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;   <span class="keyword">asm</span>(<span class="stringliteral">&quot;ld.global.cs.f32 %0,[%1];\n&quot;</span></div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;       : <span class="stringliteral">&quot;=f&quot;</span>(tmp) : <span class="stringliteral">&quot;l&quot;</span>(addr) : );</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;<span class="preprocessor">#else</span></div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;   <span class="keyword">asm</span>(<span class="stringliteral">&quot;ld.global.cs.f64 %0,[%1];\n&quot;</span></div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;       : <span class="stringliteral">&quot;=d&quot;</span>(tmp) : <span class="stringliteral">&quot;l&quot;</span>(addr) : );</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;   <span class="keywordflow">return</span> tmp;</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;}</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="ttc" id="integrate__sd__cuda__device_8hpp_html"><div class="ttname"><a href="integrate__sd__cuda__device_8hpp.html">integrate_sd_cuda_device.hpp</a></div></div>
<div class="ttc" id="integrate__sd__cuda__device_8cu_html_a7a73685d7bc0937fcbfe8fe789d59512"><div class="ttname"><a href="integrate__sd__cuda__device_8cu.html#a7a73685d7bc0937fcbfe8fe789d59512">atomicAdd</a></div><div class="ttdeci">__device__ double atomicAdd(double *address, double inc)</div><div class="ttdoc">atomic add for doubles address : pointer to which the value should be added inc : value which should ...</div><div class="ttdef"><b>Definition:</b> <a href="integrate__sd__cuda__device_8cu_source.html#l00034">integrate_sd_cuda_device.cu:34</a></div></div>
<div class="ttc" id="integrate__sd__cuda__device_8cu_html_a2b80c8d16b0b0b8e9cd3a4f785980099"><div class="ttname"><a href="integrate__sd__cuda__device_8cu.html#a2b80c8d16b0b0b8e9cd3a4f785980099">fold_back_up</a></div><div class="ttdeci">__device__ __inline__ int fold_back_up(int value, int max)</div><div class="ttdoc">modulo function for integers as implemented in python returns value % max which is always positive ...</div><div class="ttdef"><b>Definition:</b> <a href="integrate__sd__cuda__device_8cu_source.html#l00052">integrate_sd_cuda_device.cu:52</a></div></div>
<div class="ttc" id="utils_8hpp_html_a5197b278b9dd88d5c7509db1a9f76a56"><div class="ttname"><a href="utils_8hpp.html#a5197b278b9dd88d5c7509db1a9f76a56">isnan</a></div><div class="ttdeci">#define isnan(a)</div><div class="ttdoc">Check if a value is NaN. </div><div class="ttdef"><b>Definition:</b> <a href="utils_8hpp_source.html#l00297">utils.hpp:297</a></div></div>
<div class="ttc" id="EwaldgpuForce_8cpp_html_afca8eb41f1c759484b22c425442d9aa1"><div class="ttname"><a href="EwaldgpuForce_8cpp.html#afca8eb41f1c759484b22c425442d9aa1">real</a></div><div class="ttdeci">ewaldgpu_real real</div><div class="ttdef"><b>Definition:</b> <a href="EwaldgpuForce_8cpp_source.html#l00015">EwaldgpuForce.cpp:15</a></div></div>
<div class="ttc" id="integrate__sd__cuda__device_8hpp_html_aa5114a4fed348a29fb92123470476b1b"><div class="ttname"><a href="integrate__sd__cuda__device_8hpp.html#aa5114a4fed348a29fb92123470476b1b">ull</a></div><div class="ttdeci">unsigned long long ull</div><div class="ttdef"><b>Definition:</b> <a href="integrate__sd__cuda__device_8hpp_source.html#l00029">integrate_sd_cuda_device.hpp:29</a></div></div>
<div class="ttc" id="integrate__sd__cuda__device_8cu_html_a1c4c3921eac299713ff0ede5406ea077"><div class="ttname"><a href="integrate__sd__cuda__device_8cu.html#a1c4c3921eac299713ff0ede5406ea077">reduce_max</a></div><div class="ttdeci">__device__ int reduce_max(int *shared_cache)</div><div class="ttdoc">reduction function returning maximum of all value. has to be called by all threads shared_cache shoul...</div><div class="ttdef"><b>Definition:</b> <a href="integrate__sd__cuda__device_8cu_source.html#l00066">integrate_sd_cuda_device.cu:66</a></div></div>
<div class="ttc" id="integrate__sd__cuda_8hpp_html"><div class="ttname"><a href="integrate__sd__cuda_8hpp.html">integrate_sd_cuda.hpp</a></div></div>
<div class="ttc" id="integrate__sd__cuda__device_8cu_html_a7448fd635b1e54545cc6800aac0e63d6"><div class="ttname"><a href="integrate__sd__cuda__device_8cu.html#a7448fd635b1e54545cc6800aac0e63d6">reduce_sum</a></div><div class="ttdeci">__device__ void reduce_sum(real *shared_cache)</div><div class="ttdoc">reduction function returning sum of all values in shared_cache[0:blockDim.x-1] has to be called by al...</div><div class="ttdef"><b>Definition:</b> <a href="integrate__sd__cuda__device_8cu_source.html#l00099">integrate_sd_cuda_device.cu:99</a></div></div>
<div class="ttc" id="integrate__sd__cuda__device_8cu_html_a577c549165753063e40436543a8b9166"><div class="ttname"><a href="integrate__sd__cuda__device_8cu.html#a577c549165753063e40436543a8b9166">read_without_caching</a></div><div class="ttdeci">__device__ __inline__ real read_without_caching(const real *addr)</div><div class="ttdoc">function to avoid caching if reading from global memory addr : address from which the value should be...</div><div class="ttdef"><b>Definition:</b> <a href="integrate__sd__cuda__device_8cu_source.html#l00114">integrate_sd_cuda_device.cu:114</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="dir_aebb8dcc11953d78e620bbef0b9e2183.html">core</a></li><li class="navelem"><a class="el" href="integrate__sd__cuda__device_8cu.html">integrate_sd_cuda_device.cu</a></li>
    <li class="footer">Generated on Fri Jun 12 2015 16:19:18 for ESPResSo 3.4-dev-1009-g69a2b86-dirty-git by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.9.1 </li>
  </ul>
</div>
</body>
</html>
